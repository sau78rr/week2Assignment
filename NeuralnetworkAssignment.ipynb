{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2laAbZ9x_2C",
        "outputId": "6fc70b68-d0f0-4dd1-c8f2-ff0d80af7d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "065OgQKEyjih",
        "outputId": "bc1c71a1-9927-4bfd-8f61-9feade72aeee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n",
            "Zip file '/content/homer_bart.zip' extracted successfully to '/content'.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to your zip file (assuming it's in the same directory as your script)\n",
        "zip_file = '/content/homer_bart.zip'\n",
        "\n",
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "print(f\"Current directory: {current_dir}\")\n",
        "\n",
        "# Open and extract the zip file\n",
        "with zipfile.ZipFile(os.path.join(current_dir, zip_file), 'r') as zip_ref:\n",
        "    zip_ref.extractall(current_dir)\n",
        "\n",
        "print(f\"Zip file '{zip_file}' extracted successfully to '{current_dir}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 4247845\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Example function to load BMP images and preprocess\n",
        "def load_images(folder_path, image_size=(64, 64)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {'homer': 0, 'bart': 1}  # Assuming 'homer' folder is class 0, 'bart' folder is class 1\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".bmp\"):\n",
        "                filepath = os.path.join(root, filename)\n",
        "                label = os.path.basename(root).lower()\n",
        "                if label in label_map:\n",
        "                    img = Image.open(filepath)\n",
        "                    img = img.resize(image_size)\n",
        "                    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
        "                    images.append(img_array)\n",
        "                    labels.append(label_map[label])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Path to your main folder containing 'homer' and 'bart' folders\n",
        "data_folder = '/content'\n",
        "\n",
        "# Load images and labels\n",
        "images, labels = load_images(data_folder)\n",
        "\n",
        "# Splitting into training and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=SEED)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(64, 64, 3)),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dense(132, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Implementing early stopping and learning rate reduction\n",
        "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001)\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, callbacks=[early_stop, reduce_lr])\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqnEuA4V0iqD",
        "outputId": "fc66b777-6d4f-46ca-8727-493391dc92b7"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 7ms/step - loss: 1.5263 - accuracy: 0.5537 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1487 - accuracy: 0.4835 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9986 - accuracy: 0.5785 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8582 - accuracy: 0.6322 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.7231 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.7603 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7027 - accuracy: 0.7190 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7389 - accuracy: 0.7107 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5746 - accuracy: 0.7975 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.8264 - lr: 0.0010\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.4266 - accuracy: 0.9259\n",
            "Test Accuracy: 92.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mN5VyWbUoYWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}